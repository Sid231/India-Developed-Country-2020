{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_dataset = 'Spark_Dataset/GDP/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_10134290/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_10134290.csv'\n",
    "HDI_dataset = 'Spark_Dataset/HDI/Human Development Index (HDI).csv'\n",
    "Infant_Mortality_dataset = 'Spark_Dataset/Infant_Mortality_Rate/API_SP.DYN.IMRT.IN_DS2_en_csv_v2_10181276/API_SP.DYN.IMRT.IN_DS2_en_csv_v2_10181276.csv'\n",
    "Life_Expectancy_dataset = 'Spark_Dataset/Life_Expectancy/API_SP.DYN.LE00.IN_DS2_en_csv_v2_10181296/API_SP.DYN.LE00.IN_DS2_en_csv_v2_10181296.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developed_countries_list():\n",
    "    dc_list = []\n",
    "    dc_list.append(\"Australia\")\n",
    "    dc_list.append(\"Austria\")\n",
    "    dc_list.append(\"Belgium\")\n",
    "    dc_list.append(\"Canada\")\n",
    "    dc_list.append(\"Cyprus\")\n",
    "    dc_list.append(\"Czech Republic\")\n",
    "    dc_list.append(\"Denmark\")\n",
    "    dc_list.append(\"Finland\")\n",
    "    dc_list.append(\"France\")\n",
    "    dc_list.append(\"Germany\")\n",
    "    dc_list.append(\"Greece\")\n",
    "    #dc_list.append(\"Hong Kong SAR, China\")\n",
    "    dc_list.append(\"Iceland\")\n",
    "    dc_list.append(\"Ireland\")\n",
    "    dc_list.append(\"Israel\")\n",
    "    dc_list.append(\"Italy\")\n",
    "    dc_list.append(\"Japan\")\n",
    "    #dc_list.append(\"Korea, Rep.\")\n",
    "    dc_list.append(\"Luxembourg\")\n",
    "    dc_list.append(\"Malta\")\n",
    "    dc_list.append(\"Netherlands\")\n",
    "    dc_list.append(\"New Zealand\")\n",
    "    dc_list.append(\"Norway\")\n",
    "    dc_list.append(\"Portugal\")\n",
    "    dc_list.append(\"Singapore\")\n",
    "    dc_list.append(\"Slovak Republic\")\n",
    "    dc_list.append(\"Slovenia\")\n",
    "    dc_list.append(\"Spain\")\n",
    "    dc_list.append(\"Sweden\")\n",
    "    dc_list.append(\"Switzerland\")\n",
    "    #dc_list.append(\"Taiwan\")\n",
    "    dc_list.append(\"United Kingdom\")\n",
    "    dc_list.append(\"United States\")\n",
    "    return dc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(GDP_dataset)\n",
    "hdi_df = spark.read.option('header','true').option('inferSchema','true').csv(HDI_dataset)\n",
    "im_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(Infant_Mortality_dataset)\n",
    "le_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(Life_Expectancy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_drop_col = []\n",
    "for i in range(3,len(hdi_df.schema.names)):\n",
    "    if(i%2 == 1):\n",
    "        hdi_drop_col.append(hdi_df.schema.names[i])\n",
    "hdi_df = hdi_df.withColumn('Country', ltrim(hdi_df.Country))\n",
    "hdi_df = hdi_df.select([column for column in hdi_df.columns if column not in hdi_drop_col])\n",
    "hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Czechia', 'Czech Republic'))\n",
    "#hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Hong Kong, China (SAR)', 'Hong Kong SAR, China'))\n",
    "#hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Korea (Republic of)', 'Korea, Rep.'))\n",
    "hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Slovakia', 'Slovak Republic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all developed countries   \n",
    "countries_list = developed_countries_list()\n",
    "# Add India among other countries for comparison and analysis\n",
    "countries_list.append(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_gdp_df = gdp_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_im_df = im_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_le_df = le_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_hdi_df = hdi_df.filter(col('Country').isin(countries_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_n = range(1960,1995)\n",
    "drop_cols_n.append(2017)\n",
    "drop_cols_s = [str(i) for i in drop_cols_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_gdp_df = developed_gdp_df.select([column for column in developed_gdp_df.columns if column not in drop_cols_s])\n",
    "developed_gdp_df = developed_gdp_df.select([column for column in developed_gdp_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(1) for i in developed_gdp_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_gdp_df2 = developed_gdp_df.select([c for c in developed_gdp_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_gdp_rdd = developed_gdp_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_gdp_rddT1 = developed_gdp_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_gdp_rddT2 = developed_gdp_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_gdp_rddT3 = developed_gdp_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_gdp_rddT4 = developed_gdp_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_gdp_transposed_df = developed_gdp_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_gdp_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_gdp_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_gdp_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_gdp_transposed_df = developed_gdp_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_im_df = developed_im_df.select([column for column in developed_im_df.columns if column not in drop_cols_s])\n",
    "developed_im_df = developed_im_df.select([column for column in developed_im_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(2) for i in developed_im_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_im_df2 = developed_im_df.select([c for c in developed_im_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_im_rdd = developed_im_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_im_rddT1 = developed_im_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_im_rddT2 = developed_im_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_im_rddT3 = developed_im_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_im_rddT4 = developed_im_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_im_transposed_df = developed_im_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_im_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_im_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_im_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_im_transposed_df = developed_im_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_le_df = developed_le_df.select([column for column in developed_le_df.columns if column not in drop_cols_s])\n",
    "developed_le_df = developed_le_df.select([column for column in developed_le_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(3) for i in developed_le_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_le_df2 = developed_le_df.select([c for c in developed_le_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_le_rdd = developed_le_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_le_rddT1 = developed_le_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_le_rddT2 = developed_le_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_le_rddT3 = developed_le_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_le_rddT4 = developed_le_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_le_transposed_df = developed_le_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_le_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_le_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_le_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_le_transposed_df = developed_le_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_hdi_df = developed_hdi_df.select([column for column in developed_hdi_df.columns if column not in drop_cols_s])\n",
    "developed_hdi_df = developed_hdi_df.select([column for column in developed_hdi_df.columns if column not in ['HDI Rank (2017)']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(4) for i in developed_hdi_df.select(\"Country\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_hdi_df2 = developed_hdi_df.select([c for c in developed_hdi_df.columns if c not in ['Country']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_hdi_rdd = developed_hdi_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_hdi_rddT1 = developed_hdi_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_hdi_rddT2 = developed_hdi_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_hdi_rddT3 = developed_hdi_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_hdi_rddT4 = developed_hdi_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_hdi_transposed_df = developed_hdi_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_hdi_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_hdi_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_gdp_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_hdi_transposed_df = developed_hdi_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumnIndex(df): \n",
    "  # Create new column names\n",
    "    oldColumns = df.schema.names\n",
    "    #print(oldColumns)\n",
    "    newColumns = oldColumns + [\"columnindex\"]\n",
    "    #print(newColumns)\n",
    "    # Add Column index\n",
    "    df_indexed = df.rdd.zipWithIndex().map(lambda (row, columnindex): \\\n",
    "                                         row + (columnindex,)).toDF(newColumns)   \n",
    "    return df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1 = ['id1', 'dogs1', 'cats1']\n",
    "columns2 = ['id2', 'dogs2', 'cats2']\n",
    "columns3 = ['id3', 'dogs3', 'cats3']\n",
    "columns4 = ['id4', 'dogs4', 'cats4']\n",
    "vals1 = [\n",
    "     (1, 2, 0),\n",
    "     (2, 0, 1),\n",
    "     (12, 10, 31),\n",
    "     (2, 10, 91),\n",
    "]\n",
    "vals2 = [\n",
    "     (3, 32, 30),\n",
    "     (23, 30, 41),\n",
    "     (12, 10, 31),\n",
    "     (52, 10, 91),\n",
    "]\n",
    "vals3 = [\n",
    "     (1, 32, 0),\n",
    "     (3, 30, 1),\n",
    "     (1, 0, 3),\n",
    "     (52, 10, 1),\n",
    "]\n",
    "vals4 = [\n",
    "     (3, 3, 3),\n",
    "     (3, 3, 4),\n",
    "     (2, 0, 3),\n",
    "     (5, 0, 9),\n",
    "]\n",
    "df11 = sqlContext.createDataFrame(vals1, columns1)\n",
    "df12 = sqlContext.createDataFrame(vals2, columns2)\n",
    "df13 = sqlContext.createDataFrame(vals3, columns3)\n",
    "df14 = sqlContext.createDataFrame(vals4, columns4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1WithIndex = addColumnIndex(df11)\n",
    "df2WithIndex = addColumnIndex(df12)\n",
    "df3WithIndex = addColumnIndex(df13)\n",
    "df4WithIndex = addColumnIndex(df14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "newone = df1WithIndex.join(df2WithIndex, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")\n",
    "newone1 = df3WithIndex.join(df4WithIndex, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11WithIndex = addColumnIndex(newone)\n",
    "df22WithIndex = addColumnIndex(newone1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df11WithIndex.join(df22WithIndex, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+\n",
      "|id1|dogs1|cats1|id2|dogs2|cats2|id3|dogs3|cats3|id4|dogs4|cats4|\n",
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+\n",
      "|  1|    2|    0|  3|   32|   30|  1|   32|    0|  3|    3|    3|\n",
      "|  2|    0|    1| 23|   30|   41|  3|   30|    1|  3|    3|    4|\n",
      "| 12|   10|   31| 12|   10|   31|  1|    0|    3|  2|    0|    3|\n",
      "|  2|   10|   91| 52|   10|   91| 52|   10|    1|  5|    0|    9|\n",
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = n.withColumn('total_col', (n.id1 + n.id2 + n.id3 + n.id4)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+---------+\n",
      "|id1|dogs1|cats1|id2|dogs2|cats2|id3|dogs3|cats3|id4|dogs4|cats4|total_col|\n",
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+---------+\n",
      "|  1|    2|    0|  3|   32|   30|  1|   32|    0|  3|    3|    3|      2.0|\n",
      "|  2|    0|    1| 23|   30|   41|  3|   30|    1|  3|    3|    4|     7.75|\n",
      "| 12|   10|   31| 12|   10|   31|  1|    0|    3|  2|    0|    3|     6.75|\n",
      "|  2|   10|   91| 52|   10|   91| 52|   10|    1|  5|    0|    9|    27.75|\n",
      "+---+-----+-----+---+-----+-----+---+-----+-----+---+-----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
