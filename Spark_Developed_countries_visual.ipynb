{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_dataset = 'Spark_Dataset/GDP/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_10134290/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_10134290.csv'\n",
    "HDI_dataset = 'Spark_Dataset/HDI/Human Development Index (HDI).csv'\n",
    "Infant_Mortality_dataset = 'Spark_Dataset/Infant_Mortality_Rate/API_SP.DYN.IMRT.IN_DS2_en_csv_v2_10181276/API_SP.DYN.IMRT.IN_DS2_en_csv_v2_10181276.csv'\n",
    "Life_Expectancy_dataset = 'Spark_Dataset/Life_Expectancy/API_SP.DYN.LE00.IN_DS2_en_csv_v2_10181296/API_SP.DYN.LE00.IN_DS2_en_csv_v2_10181296.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developed_countries_list():\n",
    "    dc_list = []\n",
    "    dc_list.append(\"Australia\")\n",
    "    dc_list.append(\"Austria\")\n",
    "    dc_list.append(\"Belgium\")\n",
    "    dc_list.append(\"Canada\")\n",
    "    dc_list.append(\"Cyprus\")\n",
    "    dc_list.append(\"Czech Republic\")\n",
    "    dc_list.append(\"Denmark\")\n",
    "    dc_list.append(\"Finland\")\n",
    "    dc_list.append(\"France\")\n",
    "    dc_list.append(\"Germany\")\n",
    "    dc_list.append(\"Greece\")\n",
    "    #dc_list.append(\"Hong Kong SAR, China\")\n",
    "    dc_list.append(\"Iceland\")\n",
    "    dc_list.append(\"Ireland\")\n",
    "    dc_list.append(\"Israel\")\n",
    "    dc_list.append(\"Italy\")\n",
    "    dc_list.append(\"Japan\")\n",
    "    #dc_list.append(\"Korea, Rep.\")\n",
    "    dc_list.append(\"Luxembourg\")\n",
    "    dc_list.append(\"Malta\")\n",
    "    dc_list.append(\"Netherlands\")\n",
    "    dc_list.append(\"New Zealand\")\n",
    "    dc_list.append(\"Norway\")\n",
    "    dc_list.append(\"Portugal\")\n",
    "    dc_list.append(\"Singapore\")\n",
    "    dc_list.append(\"Slovak Republic\")\n",
    "    dc_list.append(\"Slovenia\")\n",
    "    dc_list.append(\"Spain\")\n",
    "    dc_list.append(\"Sweden\")\n",
    "    dc_list.append(\"Switzerland\")\n",
    "    #dc_list.append(\"Taiwan\")\n",
    "    dc_list.append(\"United Kingdom\")\n",
    "    dc_list.append(\"United States\")\n",
    "    return dc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumnIndex(df): \n",
    "    oldColumns = df.schema.names\n",
    "    newColumns = oldColumns + [\"columnindex\"]\n",
    "    df_indexed = df.rdd.zipWithIndex().map(lambda (row, columnindex): \\\n",
    "                                         row + (columnindex,)).toDF(newColumns)   \n",
    "    return df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(GDP_dataset)\n",
    "hdi_df = spark.read.option('header','true').option('inferSchema','true').csv(HDI_dataset)\n",
    "im_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(Infant_Mortality_dataset)\n",
    "le_df = spark.read.option('header','true').option('sep', '\\t').option('inferSchema','true').csv(Life_Expectancy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_drop_col = []\n",
    "for i in range(3,len(hdi_df.schema.names)):\n",
    "    if(i%2 == 1):\n",
    "        hdi_drop_col.append(hdi_df.schema.names[i])\n",
    "hdi_df = hdi_df.withColumn('Country', ltrim(hdi_df.Country))\n",
    "hdi_df = hdi_df.select([column for column in hdi_df.columns if column not in hdi_drop_col])\n",
    "hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Czechia', 'Czech Republic'))\n",
    "#hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Hong Kong, China (SAR)', 'Hong Kong SAR, China'))\n",
    "#hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Korea (Republic of)', 'Korea, Rep.'))\n",
    "hdi_df = hdi_df.withColumn('Country', regexp_replace('Country', 'Slovakia', 'Slovak Republic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all developed countries   \n",
    "countries_list = developed_countries_list()\n",
    "# Add India among other countries for comparison and analysis\n",
    "countries_list.append(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_gdp_df = gdp_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_im_df = im_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_le_df = le_df.filter(col('Country Name').isin(countries_list))\n",
    "developed_hdi_df = hdi_df.filter(col('Country').isin(countries_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_n = range(1960,1995)\n",
    "drop_cols_n.append(2017)\n",
    "drop_cols_s = [str(i) for i in drop_cols_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_gdp_df = developed_gdp_df.select([column for column in developed_gdp_df.columns if column not in drop_cols_s])\n",
    "developed_gdp_df = developed_gdp_df.select([column for column in developed_gdp_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(1) for i in developed_gdp_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_gdp_df2 = developed_gdp_df.select([c for c in developed_gdp_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_gdp_rdd = developed_gdp_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_gdp_rddT1 = developed_gdp_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_gdp_rddT2 = developed_gdp_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_gdp_rddT3 = developed_gdp_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_gdp_rddT4 = developed_gdp_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_gdp_transposed_df = developed_gdp_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_gdp_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_gdp_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_gdp_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_gdp_transposed_df = developed_gdp_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_im_df = developed_im_df.select([column for column in developed_im_df.columns if column not in drop_cols_s])\n",
    "developed_im_df = developed_im_df.select([column for column in developed_im_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(2) for i in developed_im_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_im_df2 = developed_im_df.select([c for c in developed_im_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_im_rdd = developed_im_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_im_rddT1 = developed_im_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_im_rddT2 = developed_im_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_im_rddT3 = developed_im_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_im_rddT4 = developed_im_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_im_transposed_df = developed_im_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_im_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_im_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_im_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_im_transposed_df = developed_im_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_le_df = developed_le_df.select([column for column in developed_le_df.columns if column not in drop_cols_s])\n",
    "developed_le_df = developed_le_df.select([column for column in developed_le_df.columns if column not in ['Country Code','Indicator Name','Indicator Code']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(3) for i in developed_le_df.select(\"Country Name\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_le_df2 = developed_le_df.select([c for c in developed_le_df.columns if c not in ['Country Name']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_le_rdd = developed_le_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_le_rddT1 = developed_le_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_le_rddT2 = developed_le_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_le_rddT3 = developed_le_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_le_rddT4 = developed_le_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_le_transposed_df = developed_le_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_le_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_le_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_le_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_le_transposed_df = developed_le_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_hdi_df = developed_hdi_df.select([column for column in developed_hdi_df.columns if column not in drop_cols_s])\n",
    "developed_hdi_df = developed_hdi_df.select([column for column in developed_hdi_df.columns if column not in ['HDI Rank (2017)']])\n",
    "\n",
    "# Grad data from first columns, since it will be transposed to new column headers\n",
    "new_header = [i[0]+str(4) for i in developed_hdi_df.select(\"Country\").rdd.map(tuple).collect()]\n",
    "\n",
    "# Remove first column from dataframe\n",
    "developed_hdi_df2 = developed_hdi_df.select([c for c in developed_hdi_df.columns if c not in ['Country']])\n",
    "\n",
    "# Convert DataFrame to RDD\n",
    "developed_hdi_rdd = developed_hdi_df2.rdd.map(tuple)\n",
    "\n",
    "# Transpose Data\n",
    "developed_hdi_rddT1 = developed_hdi_rdd.zipWithIndex().flatMap(lambda (x,i): [(i,j,e) for (j,e) in enumerate(x)])\n",
    "developed_hdi_rddT2 = developed_hdi_rddT1.map(lambda (i,j,e): (j, (i,e))).groupByKey().sortByKey()\n",
    "developed_hdi_rddT3 = developed_hdi_rddT2.map(lambda (i, x): sorted(list(x), cmp=lambda (i1,e1),(i2,e2) : cmp(i1, i2)))\n",
    "developed_hdi_rddT4 = developed_hdi_rddT3.map(lambda x: map(lambda (i, y): y , x))\n",
    "\n",
    "# Convert back to DataFrame (along with header)\n",
    "developed_hdi_transposed_df = developed_hdi_rddT4.toDF(new_header)\n",
    "\n",
    "#Normalize the columns\n",
    "for field in developed_hdi_transposed_df.schema.fields:\n",
    "    if str(field.dataType) in ['DoubleType', 'FloatType', 'LongType', 'IntegerType', 'DecimalType']:\n",
    "        name = str(field.name)\n",
    "        divider = developed_hdi_transposed_df.agg({name: \"max\"}).collect()[0][0]\n",
    "        #developed_gdp_transposed_df.groupBy().sum().collect()[0][\"sum(\"+name+\")\"]\n",
    "        developed_hdi_transposed_df = developed_hdi_transposed_df.withColumn(name, col(name)/divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_gdp_transposed_df_WithIndex = addColumnIndex(developed_gdp_transposed_df)\n",
    "developed_le_transposed_df_WithIndex = addColumnIndex(developed_le_transposed_df)\n",
    "developed_im_transposed_df_WithIndex = addColumnIndex(developed_im_transposed_df)\n",
    "developed_hdi_transposed_df_WithIndex = addColumnIndex(developed_hdi_transposed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_1 = developed_gdp_transposed_df_WithIndex.join(developed_le_transposed_df_WithIndex, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")\n",
    "merge_2 = developed_im_transposed_df_WithIndex.join(developed_hdi_transposed_df_WithIndex, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")\n",
    "merge_1_Index = addColumnIndex(merge_1)\n",
    "merge_2_Index = addColumnIndex(merge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = [i[0] for i in developed_hdi_df.select(\"Country\").rdd.map(tuple).collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_df_countries = merge_1_Index.join(merge_2_Index, (\"columnindex\"),\n",
    "                           'inner').drop(\"columnindex\")\n",
    "\n",
    "for country in new_header:\n",
    "    grand_df_countries = grand_df_countries.withColumn(country, (grand_df_countries[(country+str(1))] + grand_df_countries[(country+str(2))] + grand_df_countries[(country+str(3))] + grand_df_countries[(country+str(4))])/4)\n",
    "    \n",
    "grand_df_countries = grand_df_countries.select([column for column in grand_df_countries.columns if column in new_header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 31)\n"
     ]
    }
   ],
   "source": [
    "print((grand_df_countries.count(), len(grand_df_countries.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
