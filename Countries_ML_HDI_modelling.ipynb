{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDrs_8JZkLEE"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import math\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZw6_CZwQwkw"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import cPickle as pickle\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vYyk2cixnnz6",
    "outputId": "85c75c27-4a4e-4ea3-87f0-760358e5ed63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5feuHCu1owt"
   },
   "source": [
    "Get the x and y values in the pickle **hdi_x_y_countries_pickle** to be trained in the GPU in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n9rAvIilR_5"
   },
   "outputs": [],
   "source": [
    "dbfile = open('/content/gdrive/My Drive/Massive Data Final Project/hdi_x_y_countries_pickle', 'rb')      \n",
    "x_y_values_db = pickle.load(dbfile) \n",
    "#print x_y_values_db['x_val']\n",
    "x_val_array = x_y_values_db['x_val']\n",
    "y_val_array = x_y_values_db['y_val']\n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8Ktsw4O1owx"
   },
   "source": [
    "Load the **RandomForestRegressor model** and split the train and test sets using train_test_split function of sklearn. <br/>\n",
    "Here, we try the Random Forest. To find the model's quality, we use the **RMSE** (Root Mean Square Error) and the **R2** score. R2 is the proportion of variability that is explained by our model. It ranges from 0-1 for maximum proportion of variability explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SqU3mEhcl8qO",
    "outputId": "e9fffe54-6b72-4300-a9f7-1da952e21ca1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.012244\n",
      "R2 score: 0.97\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(random_state=21)\n",
    "train_X, test_X, train_y, test_y = train_test_split(x_val_array, y_val_array, test_size=0.25, random_state=21)\n",
    "rmse= np.sqrt(np.mean(-cross_val_score(forest_model, train_X, train_y,cv=5,  scoring='neg_mean_squared_error')))\n",
    "print(\"RMSE : %f\" % (rmse))\n",
    "r2_score1= np.mean(cross_val_score(forest_model, train_X, train_y,cv=5,  scoring='r2'))\n",
    "print(\"R2 score: %s\" % '{:.2}'.format(r2_score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrHhrFAG1ow2"
   },
   "source": [
    "We need the best parameters for our **RandomForestRegressor**. We try to find them using **RandomSearchCV** followed by **GridSearchCV**. RandomSearchCV helps to narrow down the number and range of parameters, which can then be tested using GridSearchCV. Here we print the best params for the model using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BYMg41Nfoi_O",
    "outputId": "da751e56-9abc-48b7-b408-139e372c46d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False], 'min_samples_leaf': [1, 2, 4], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'min_samples_split': [2, 5, 10], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]}\n"
     ]
    }
   ],
   "source": [
    "number_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': number_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jLmEAgBYosx1",
    "outputId": "4088bf73-d39a-4e47-b0c3-48a88963a21b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 110}\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(random_state=21)\n",
    "rf_random = RandomizedSearchCV(estimator = forest_model, param_distributions = random_grid, \n",
    "                          cv = 5, n_jobs = -1,n_iter = 20, verbose = 0)\n",
    "rf_random.fit(train_X, train_y)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "St11FvUY1ow9"
   },
   "source": [
    "Random search helps to narrow down the range for all the hyperparameters. This is then followed by **GridSearch CV** where we can test all the combinations of the parameters unlike Random search. Here we find best params for the model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_9dHAeEFovl3",
    "outputId": "0b1b72c0-4ada-40f7-d4a4-628bfb25456f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 1000, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [40, 75, 100, 120],\n",
    "              'max_features': ['sqrt'],\n",
    "              'min_samples_leaf': [1, 3, 4, 5],\n",
    "              'min_samples_split': [2, 4, 8],\n",
    "              'n_estimators': [200, 400, 600, 800, 1000],\n",
    "             'bootstrap': [False, True]}\n",
    "# Create a basic model\n",
    "rf = RandomForestRegressor(random_state=21)\n",
    "# Instantiate the grid search model\n",
    "rf_grid = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 0)\n",
    "rf_grid.fit(train_X, train_y)\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-HU4uvZ27CA"
   },
   "source": [
    "Print the **RMSE** and **R2 score** of the Random Forest Regressor model to predict **HDI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8XQut_dermMi",
    "outputId": "cb41186d-6962-4842-bcea-baf0aa3df9a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.008203\n",
      "R2 score: 0.98\n"
     ]
    }
   ],
   "source": [
    "rf_cv_random=RandomForestRegressor(random_state=21,n_estimators= 1000, min_samples_split= 2, min_samples_leaf= 1, max_features= 'sqrt', max_depth= 40, bootstrap= False)\n",
    "rf_cv_random.fit(train_X,train_y )\n",
    "predictions=rf_cv_random.predict(test_X)\n",
    "rmse3 = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "print(\"RMSE : %f\" % (rmse3))\n",
    "r23= r2_score(test_y,predictions)\n",
    "print(\"R2 score: %s\" % '{:.2}'.format(r23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nK2dNLv2v6K"
   },
   "source": [
    "Compute errors and accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdax1X6e14DP"
   },
   "outputs": [],
   "source": [
    "hdi_errors = math.fabs(np.mean(predictions/test_y - 1))\n",
    "hdi_mape = 100 * (hdi_errors)\n",
    "hdi_accuracy = 100 - hdi_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GqtBpGnq2oQl",
    "outputId": "125af341-5f39-41e5-ce42-c0a08b2f7012"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.9152805546158"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdi_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGBoJs0m2994"
   },
   "source": [
    "Save the states and the model in the **hdi_randomForestRegressor_pickle** pickle and upload in gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nq9lL8ec6Txd"
   },
   "outputs": [],
   "source": [
    "hdi_randomForestRegressor_db = {} \n",
    "hdi_randomForestRegressor_db['forest_model'] = forest_model\n",
    "hdi_randomForestRegressor_db['rf_random'] = rf_random\n",
    "hdi_randomForestRegressor_db['rf_grid'] = rf_grid\n",
    "hdi_randomForestRegressor_db['rf_cv_random'] = rf_cv_random\n",
    "hdi_randomForestRegressor_db['predictions'] = predictions\n",
    "hdi_randomForestRegressor_db['rmse3'] = rmse3\n",
    "hdi_randomForestRegressor_db['r23'] = r23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nQ66A6d7K44"
   },
   "outputs": [],
   "source": [
    "hdi_randomForestRegressor_dbfile = open('hdi_randomForestRegressor_pickle', 'ab') \n",
    "# source, destination \n",
    "pickle.dump(hdi_randomForestRegressor_db, hdi_randomForestRegressor_dbfile)                      \n",
    "hdi_randomForestRegressor_dbfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P_MagHzwRwtO",
    "outputId": "5d33afa1-b046-4b98-a7d7-533558ba01c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1hBvMrI1cp86WvZxYciLHve1hCd-wP9P0\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "gdrive = GoogleDrive(gauth)\n",
    "\n",
    "# Create & upload a file.\n",
    "uploaded = gdrive.CreateFile({'title': 'hdi_randomForestRegressor_pickle'})\n",
    "uploaded.SetContentFile('hdi_randomForestRegressor_pickle')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Countries_ML_HDI_modelling.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
